program: run_finetuning.py
project: CoRT
description: Representation Hyperparameters Tuning using Bayes Search for CoRT
method: bayes
metric:
  name: val_total_loss
  goal: minimize
parameters:
  cross_validation:
    value: hyperparams
  repr_size:
    value: 1024
  repr_classifier:
    values:
      - seq_cls
      - bi_lstm
  repr_act:
    values:
      - none
      - tanh
      - swish
      - gelu
  repr_preact:
    values: [False, True]
  loss_base:
    values:
      - margin
      - supervised
  learning_rate:
    distribution: uniform
    min: 0.00001
    max: 0.0001
  lr_fn:
    values:
      - cosine_decay
      - polynomial_decay
      - linear_decay
  layerwise_lr_decay:
    distribution: uniform
    min: 0.6
    max: 0.9
  weight_decay:
    distribution: uniform
    min: 0
    max: 0.01
  backbone_trainable_layers:
    values: [0, 1]
  alpha:
    distribution: uniform
    min: 1.5
    max: 5.0
  batch_size:
    values: [16, 32]
  gradient_accumulation_steps:
    distribution: int_uniform
    min: 1
    max: 6
